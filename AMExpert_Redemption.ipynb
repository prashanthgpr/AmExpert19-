{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures, RobustScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import logit\n",
    "\n",
    "#train, test, campaign_data, coupon_item_mapping, customer_demographics, customer_transaction_data,item_data,submission,\n",
    "\n",
    "\n",
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test_QyjYwdj.csv\")\n",
    "campaign_data=pd.read_csv(\"campaign_data.csv\")\n",
    "coupon_item_mapping=pd.read_csv(\"coupon_item_mapping.csv\")\n",
    "customer_demographics=pd.read_csv(\"customer_demographics.csv\")\n",
    "customer_transaction_data=pd.read_csv(\"customer_transaction_data.csv\")\n",
    "item_data=pd.read_csv(\"item_data.csv\")\n",
    "submission=pd.read_csv(\"sample_submission_Byiv0dS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_length: 78369\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([train, test], sort=False).reset_index(drop = True)\n",
    "print (\"Train_length:\", len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(campaign_data, on='campaign_id')#  campaign_data\n",
    "data['start_date'] = pd.to_datetime(data['start_date'], dayfirst=True)\n",
    "data['end_date'] = pd.to_datetime(data['end_date'], dayfirst=True)\n",
    "data['campaign_type'] = pd.Series(data['campaign_type'].factorize()[0]).replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_demographics\n",
    "# customer_demographics\n",
    "customer_demographics['no_of_children'] = customer_demographics['no_of_children'].replace('3+', 3).astype(float)\n",
    "customer_demographics['family_size'] = customer_demographics['family_size'].replace('5+', 3).astype(float)\n",
    "customer_demographics['marital_status'] = pd.Series(customer_demographics['marital_status'].factorize()[0]).replace(-1, np.nan)\n",
    "customer_demographics['age_range'] = pd.Series(customer_demographics['age_range'].factorize()[0]).replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rented\n",
    "rented_mean = customer_demographics.groupby(\"customer_id\")['rented'].mean().to_dict()\n",
    "data['rented_mean'] = data['customer_id'].map(rented_mean)\n",
    "# income_bracket\n",
    "income_bracket_sum = customer_demographics.groupby(\"customer_id\")['income_bracket'].sum().to_dict()\n",
    "data['income_bracket_sum'] = data['customer_id'].map(income_bracket_sum)\n",
    "# age_range\n",
    "age_range_mean = customer_demographics.groupby(\"customer_id\")['age_range'].mean().to_dict()\n",
    "data['age_range_mean'] = data['customer_id'].map(age_range_mean)\n",
    "# family_size\n",
    "family_size_mean = customer_demographics.groupby(\"customer_id\")['family_size'].mean().to_dict()\n",
    "data['family_size_mean'] = data['customer_id'].map(family_size_mean)\n",
    "# no_of_children\n",
    "no_of_children_mean = customer_demographics.groupby(\"customer_id\")['no_of_children'].mean().to_dict()\n",
    "data['no_of_children_mean'] = data['customer_id'].map(no_of_children_mean)\n",
    "no_of_children_count = customer_demographics.groupby(\"customer_id\")['no_of_children'].count().to_dict()\n",
    "data['no_of_children_count'] = data['customer_id'].map(no_of_children_count)\n",
    "# marital_status\n",
    "marital_status_count = customer_demographics.groupby(\"customer_id\")['marital_status'].count().to_dict()\n",
    "data['marital_status_count'] = data['customer_id'].map(marital_status_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# customer_transaction_data\n",
    "customer_transaction_data['date'] = pd.to_datetime(customer_transaction_data['date'])\n",
    "# quantity\t\n",
    "quantity_mean = customer_transaction_data.groupby(\"customer_id\")['quantity'].mean().to_dict()\n",
    "data['quantity_mean'] = data['customer_id'].map(quantity_mean)\n",
    "#coupon_discount\n",
    "coupon_discount_mean = customer_transaction_data.groupby(\"customer_id\")['coupon_discount'].mean().to_dict()\n",
    "data['coupon_discount_mean'] = data['customer_id'].map(coupon_discount_mean)\n",
    "# other_discount\n",
    "other_discount_mean = customer_transaction_data.groupby(\"customer_id\")['other_discount'].mean().to_dict()\n",
    "data['other_discount_mean'] = data['customer_id'].map(other_discount_mean)\n",
    "# day\n",
    "customer_transaction_data['day'] = customer_transaction_data.date.dt.day\n",
    "date_day_mean = customer_transaction_data.groupby(\"customer_id\")['day'].mean().to_dict()\n",
    "data['date_day_mean'] = data['customer_id'].map(date_day_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coupon_item_mapping, item_data\n",
    "coupon_item_mapping = coupon_item_mapping.merge(item_data, how = 'left', on = 'item_id')\n",
    "coupon_item_mapping['brand_type'] = pd.Series(coupon_item_mapping['brand_type'].factorize()[0]).replace(-1, np.nan)\n",
    "coupon_item_mapping['category'] = pd.Series(coupon_item_mapping['category'].factorize()[0]).replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].mean().to_dict()\n",
    "data['category_mean'] = data['coupon_id'].map(category)\n",
    "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].count().to_dict()\n",
    "data['category_count'] = data['coupon_id'].map(category)\n",
    "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].nunique().to_dict()\n",
    "data['category_nunique'] = data['coupon_id'].map(category)\n",
    "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].max().to_dict()\n",
    "data['category_max'] = data['coupon_id'].map(category)\n",
    "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].min().to_dict()\n",
    "data['category_min'] = data['coupon_id'].map(category)\n",
    "\n",
    "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].mean().to_dict()\n",
    "data['brand_mean'] = data['coupon_id'].map(brand_mean)\n",
    "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].count().to_dict()\n",
    "data['brand_count'] = data['coupon_id'].map(brand_mean)\n",
    "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].min().to_dict()\n",
    "data['brand_min'] = data['coupon_id'].map(brand_mean)\n",
    "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].max().to_dict()\n",
    "data['brand_max'] = data['coupon_id'].map(brand_mean)\n",
    "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].nunique().to_dict()\n",
    "data['brand_nunique'] = data['coupon_id'].map(brand_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selling_price\n",
    "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].mean().to_dict()\n",
    "data['selling_price_mean'] = data['customer_id'].map(selling_price_mean)\n",
    "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].sum().to_dict()\n",
    "data['selling_price_sum'] = data['customer_id'].map(selling_price_mean)\n",
    "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].min().to_dict()\n",
    "data['selling_price_min'] = data['customer_id'].map(selling_price_mean)\n",
    "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].max().to_dict()\n",
    "data['selling_price_max'] = data['customer_id'].map(selling_price_mean)\n",
    "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].nunique().to_dict()\n",
    "data['selling_price_nunique'] = data['customer_id'].map(selling_price_mean)\n",
    "train_cols = [i for i in data.columns if i not in ['id','redemption_status','start_date','end_date']]\n",
    "train_cols = ['campaign_id','coupon_id','campaign_type','rented_mean','income_bracket_sum','age_range_mean','family_size_mean',\n",
    " 'no_of_children_mean',\n",
    " 'no_of_children_count',\n",
    " 'marital_status_count',\n",
    " 'quantity_mean',\n",
    " 'coupon_discount_mean',\n",
    " 'other_discount_mean',\n",
    " 'date_day_mean',\n",
    " 'category_mean',\n",
    " 'category_nunique',\n",
    " 'category_max',\n",
    " 'category_min',\n",
    " 'brand_mean',\n",
    " 'brand_max',\n",
    " 'brand_nunique',\n",
    " 'selling_price_mean',\n",
    " 'selling_price_min',\n",
    " 'selling_price_nunique']\n",
    "train = data[data['redemption_status'].notnull()]\n",
    "test = data[data['redemption_status'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>redemption_status</th>\n",
       "      <th>campaign_type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>rented_mean</th>\n",
       "      <th>income_bracket_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_mean</th>\n",
       "      <th>brand_count</th>\n",
       "      <th>brand_min</th>\n",
       "      <th>brand_max</th>\n",
       "      <th>brand_nunique</th>\n",
       "      <th>selling_price_mean</th>\n",
       "      <th>selling_price_sum</th>\n",
       "      <th>selling_price_min</th>\n",
       "      <th>selling_price_max</th>\n",
       "      <th>selling_price_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>1053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-19</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1364.128</td>\n",
       "      <td>125</td>\n",
       "      <td>1105</td>\n",
       "      <td>1636</td>\n",
       "      <td>2</td>\n",
       "      <td>184.260484</td>\n",
       "      <td>57120.75</td>\n",
       "      <td>17.45</td>\n",
       "      <td>5164.54</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>116</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-19</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.000</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>234.247013</td>\n",
       "      <td>90185.10</td>\n",
       "      <td>7.12</td>\n",
       "      <td>1758.92</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>644</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-19</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>611.000</td>\n",
       "      <td>4</td>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "      <td>1</td>\n",
       "      <td>98.276034</td>\n",
       "      <td>23291.42</td>\n",
       "      <td>13.89</td>\n",
       "      <td>708.48</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>1028</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-19</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1639.000</td>\n",
       "      <td>6</td>\n",
       "      <td>1639</td>\n",
       "      <td>1639</td>\n",
       "      <td>1</td>\n",
       "      <td>115.576332</td>\n",
       "      <td>77204.99</td>\n",
       "      <td>10.33</td>\n",
       "      <td>1246.70</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>517</td>\n",
       "      <td>1067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-19</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>261.000</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>115.829742</td>\n",
       "      <td>112354.85</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1905.31</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  campaign_id  coupon_id  customer_id  redemption_status  campaign_type  \\\n",
       "0   1           13         27         1053                0.0              0   \n",
       "1   2           13        116           48                0.0              0   \n",
       "2   7           13        644         1050                0.0              0   \n",
       "3  21           13       1028           89                0.0              0   \n",
       "4  23           13        517         1067                0.0              0   \n",
       "\n",
       "  start_date   end_date  rented_mean  income_bracket_sum  ...  brand_mean  \\\n",
       "0 2013-05-19 2013-07-05          0.0                 5.0  ...    1364.128   \n",
       "1 2013-05-19 2013-07-05          0.0                 3.0  ...      56.000   \n",
       "2 2013-05-19 2013-07-05          NaN                 NaN  ...     611.000   \n",
       "3 2013-05-19 2013-07-05          0.0                 3.0  ...    1639.000   \n",
       "4 2013-05-19 2013-07-05          0.0                 5.0  ...     261.000   \n",
       "\n",
       "   brand_count  brand_min  brand_max  brand_nunique  selling_price_mean  \\\n",
       "0          125       1105       1636              2          184.260484   \n",
       "1            3         56         56              1          234.247013   \n",
       "2            4        611        611              1           98.276034   \n",
       "3            6       1639       1639              1          115.576332   \n",
       "4            3        261        261              1          115.829742   \n",
       "\n",
       "   selling_price_sum  selling_price_min  selling_price_max  \\\n",
       "0           57120.75              17.45            5164.54   \n",
       "1           90185.10               7.12            1758.92   \n",
       "2           23291.42              13.89             708.48   \n",
       "3           77204.99              10.33            1246.70   \n",
       "4          112354.85               3.56            1905.31   \n",
       "\n",
       "   selling_price_nunique  \n",
       "0                    129  \n",
       "1                    114  \n",
       "2                     84  \n",
       "3                    186  \n",
       "4                    186  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50226, 34)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50226, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from category_encoders import TargetEncoder\n",
    "def run_cv_model(train, test, target, model_fn, params={}, eval_fn=None, label='model', n_folds=5):\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle = True, random_state = 228)\n",
    "    fold_splits = kf.split(train, target)\n",
    "    cv_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros((train.shape[0]))\n",
    "    feature_importances = pd.DataFrame()\n",
    "    feature_importances['feature'] = test.columns\n",
    "    i = 1\n",
    "    for dev_index, val_index in fold_splits:\n",
    "        print('-------------------------------------------')\n",
    "        print('Started ' + label + ' fold ' + str(i) + f'/{n_folds}')\n",
    "        dev_X, val_X = train.iloc[dev_index], train.iloc[val_index]\n",
    "        dev_y, val_y = target.iloc[dev_index], target.iloc[val_index]\n",
    "        params2 = params.copy()\n",
    "        pred_val_y, pred_test_y, fi = model_fn(dev_X, dev_y, val_X, val_y, test, params2)\n",
    "        feature_importances[f'fold_{i}'] = fi\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index] = pred_val_y\n",
    "        if eval_fn is not None:\n",
    "            cv_score = eval_fn(val_y, pred_val_y)\n",
    "            cv_scores.append(cv_score)\n",
    "            print(label + ' cv score {}: {}'.format(i, cv_score), '\\n')\n",
    "        i += 1\n",
    "    print('{} cv scores : {}'.format(label, cv_scores))\n",
    "    print('{} cv mean score : {}'.format(label, np.mean(cv_scores)))\n",
    "    print('{} cv std score : {}'.format(label, np.std(cv_scores)))\n",
    "    pred_full_test = pred_full_test / n_folds\n",
    "    results = {'label': label,\n",
    "              'train': pred_train, 'test': pred_full_test,\n",
    "              'cv': cv_scores, 'fi': feature_importances}\n",
    "    return results\n",
    "\n",
    "\n",
    "def runCAT(train_X, train_y, test_X, test_y, test_X2, params):\n",
    "    # Pool the data and specify the categorical feature indices\n",
    "    print('Pool Data')\n",
    "    _train = Pool(train_X, label=train_y)\n",
    "    _valid = Pool(test_X, label=test_y)    \n",
    "    print('Train CAT')\n",
    "    model = CatBoostClassifier(**params)\n",
    "    fit_model = model.fit(_train,\n",
    "                          eval_set=_valid,\n",
    "                          use_best_model=True,\n",
    "                          verbose=1000,\n",
    "                          plot=False)\n",
    "    feature_im = fit_model.feature_importances_\n",
    "    print('Predict 1/2')\n",
    "    pred_test_y = logit(fit_model.predict_proba(test_X)[:, 1])\n",
    "    print('Predict 2/2')\n",
    "    pred_test_y2 = logit(fit_model.predict_proba(test_X2)[:, 1])\n",
    "    return pred_test_y, pred_test_y2, feature_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Started cat fold 1/10\n",
      "Pool Data\n",
      "Train CAT\n",
      "0:\ttest: 0.6800045\tbest: 0.6800045 (0)\ttotal: 217ms\tremaining: 36m 10s\n",
      "1000:\ttest: 0.9241176\tbest: 0.9241529 (998)\ttotal: 51.1s\tremaining: 7m 39s\n",
      "2000:\ttest: 0.9284086\tbest: 0.9285127 (1979)\ttotal: 1m 37s\tremaining: 6m 29s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9289273288\n",
      "bestIteration = 2290\n",
      "\n",
      "Shrink model to first 2291 iterations.\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "cat cv score 1: 0.9289273288024108 \n",
      "\n",
      "-------------------------------------------\n",
      "Started cat fold 2/10\n",
      "Pool Data\n",
      "Train CAT\n",
      "0:\ttest: 0.6983628\tbest: 0.6983628 (0)\ttotal: 61.5ms\tremaining: 10m 15s\n",
      "1000:\ttest: 0.9147488\tbest: 0.9147629 (999)\ttotal: 47.8s\tremaining: 7m 9s\n",
      "2000:\ttest: 0.9235424\tbest: 0.9235795 (1992)\ttotal: 1m 34s\tremaining: 6m 16s\n",
      "3000:\ttest: 0.9271541\tbest: 0.9272653 (2943)\ttotal: 2m 20s\tremaining: 5m 28s\n",
      "4000:\ttest: 0.9288162\tbest: 0.9288479 (3995)\ttotal: 3m 7s\tremaining: 4m 40s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9298624491\n",
      "bestIteration = 4359\n",
      "\n",
      "Shrink model to first 4360 iterations.\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "cat cv score 2: 0.9298624490976971 \n",
      "\n",
      "-------------------------------------------\n",
      "Started cat fold 3/10\n",
      "Pool Data\n",
      "Train CAT\n",
      "0:\ttest: 0.7449433\tbest: 0.7449433 (0)\ttotal: 52.3ms\tremaining: 8m 42s\n",
      "1000:\ttest: 0.9139107\tbest: 0.9139107 (1000)\ttotal: 1m\tremaining: 9m 7s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9162626241\n",
      "bestIteration = 1520\n",
      "\n",
      "Shrink model to first 1521 iterations.\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "cat cv score 3: 0.9162626241239864 \n",
      "\n",
      "-------------------------------------------\n",
      "Started cat fold 4/10\n",
      "Pool Data\n",
      "Train CAT\n",
      "0:\ttest: 0.7084189\tbest: 0.7084189 (0)\ttotal: 125ms\tremaining: 20m 48s\n",
      "1000:\ttest: 0.9428200\tbest: 0.9428200 (1000)\ttotal: 52.5s\tremaining: 7m 52s\n",
      "2000:\ttest: 0.9529599\tbest: 0.9529599 (2000)\ttotal: 1m 40s\tremaining: 6m 40s\n",
      "3000:\ttest: 0.9583783\tbest: 0.9584718 (2977)\ttotal: 2m 26s\tremaining: 5m 40s\n",
      "4000:\ttest: 0.9611449\tbest: 0.9611449 (4000)\ttotal: 3m 12s\tremaining: 4m 48s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9613318936\n",
      "bestIteration = 4087\n",
      "\n",
      "Shrink model to first 4088 iterations.\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "cat cv score 4: 0.9613318936009542 \n",
      "\n",
      "-------------------------------------------\n",
      "Started cat fold 5/10\n",
      "Pool Data\n",
      "Train CAT\n",
      "0:\ttest: 0.7067463\tbest: 0.7067463 (0)\ttotal: 57.7ms\tremaining: 9m 36s\n",
      "1000:\ttest: 0.8962705\tbest: 0.8962705 (1000)\ttotal: 51.7s\tremaining: 7m 44s\n",
      "2000:\ttest: 0.9059816\tbest: 0.9059816 (2000)\ttotal: 1m 47s\tremaining: 7m 8s\n",
      "3000:\ttest: 0.9094239\tbest: 0.9094856 (2998)\ttotal: 2m 41s\tremaining: 6m 16s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9097873572\n",
      "bestIteration = 3173\n",
      "\n",
      "Shrink model to first 3174 iterations.\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "cat cv score 5: 0.9097873571736077 \n",
      "\n",
      "-------------------------------------------\n",
      "Started cat fold 6/10\n",
      "Pool Data\n",
      "Train CAT\n",
      "0:\ttest: 0.6962376\tbest: 0.6962376 (0)\ttotal: 60.9ms\tremaining: 10m 8s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9057751618\n",
      "bestIteration = 60\n",
      "\n",
      "Shrink model to first 61 iterations.\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "cat cv score 6: 0.9057751617934549 \n",
      "\n",
      "-------------------------------------------\n",
      "Started cat fold 7/10\n",
      "Pool Data\n",
      "Train CAT\n",
      "0:\ttest: 0.6799639\tbest: 0.6799639 (0)\ttotal: 67.8ms\tremaining: 11m 17s\n",
      "1000:\ttest: 0.9160403\tbest: 0.9160438 (993)\ttotal: 46.3s\tremaining: 6m 56s\n",
      "2000:\ttest: 0.9228649\tbest: 0.9228685 (1993)\ttotal: 1m 31s\tremaining: 6m 7s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9265365967\n",
      "bestIteration = 2838\n",
      "\n",
      "Shrink model to first 2839 iterations.\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "cat cv score 7: 0.9265365967267261 \n",
      "\n",
      "-------------------------------------------\n",
      "Started cat fold 8/10\n",
      "Pool Data\n",
      "Train CAT\n",
      "0:\ttest: 0.6610683\tbest: 0.6610683 (0)\ttotal: 67.2ms\tremaining: 11m 12s\n",
      "1000:\ttest: 0.9152181\tbest: 0.9152234 (997)\ttotal: 46.2s\tremaining: 6m 55s\n",
      "2000:\ttest: 0.9209118\tbest: 0.9209365 (1989)\ttotal: 1m 33s\tremaining: 6m 14s\n",
      "3000:\ttest: 0.9237012\tbest: 0.9240065 (2914)\ttotal: 2m 20s\tremaining: 5m 27s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9243011299\n",
      "bestIteration = 3115\n",
      "\n",
      "Shrink model to first 3116 iterations.\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "cat cv score 8: 0.9243011299076171 \n",
      "\n",
      "-------------------------------------------\n",
      "Started cat fold 9/10\n",
      "Pool Data\n",
      "Train CAT\n",
      "0:\ttest: 0.6314647\tbest: 0.6314647 (0)\ttotal: 57.6ms\tremaining: 9m 35s\n",
      "1000:\ttest: 0.9042225\tbest: 0.9042331 (999)\ttotal: 46.9s\tremaining: 7m 1s\n",
      "2000:\ttest: 0.9139460\tbest: 0.9139460 (2000)\ttotal: 1m 33s\tremaining: 6m 13s\n",
      "3000:\ttest: 0.9183728\tbest: 0.9183728 (3000)\ttotal: 2m 19s\tremaining: 5m 24s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9197313911\n",
      "bestIteration = 3799\n",
      "\n",
      "Shrink model to first 3800 iterations.\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "cat cv score 9: 0.9197313911061238 \n",
      "\n",
      "-------------------------------------------\n",
      "Started cat fold 10/10\n",
      "Pool Data\n",
      "Train CAT\n",
      "0:\ttest: 0.8304336\tbest: 0.8304336 (0)\ttotal: 49.8ms\tremaining: 8m 17s\n",
      "1000:\ttest: 0.9372156\tbest: 0.9372639 (998)\ttotal: 49.8s\tremaining: 7m 28s\n",
      "2000:\ttest: 0.9449060\tbest: 0.9449060 (2000)\ttotal: 1m 43s\tremaining: 6m 53s\n",
      "3000:\ttest: 0.9484265\tbest: 0.9484283 (2994)\ttotal: 2m 37s\tremaining: 6m 7s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9495588614\n",
      "bestIteration = 3772\n",
      "\n",
      "Shrink model to first 3773 iterations.\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "cat cv score 10: 0.9495588614116435 \n",
      "\n",
      "cat cv scores : [0.9289273288024108, 0.9298624490976971, 0.9162626241239864, 0.9613318936009542, 0.9097873571736077, 0.9057751617934549, 0.9265365967267261, 0.9243011299076171, 0.9197313911061238, 0.9495588614116435]\n",
      "cat cv mean score : 0.9272074793744223\n",
      "cat cv std score : 0.016190893332196112\n"
     ]
    }
   ],
   "source": [
    "# Use some baseline parameters\n",
    "cat_params = {'loss_function': 'CrossEntropy', \n",
    "              'eval_metric': \"AUC\",\n",
    "              'learning_rate': 0.01,\n",
    "              'iterations': 10000,\n",
    "              'random_seed': 42,\n",
    "              'od_type': \"Iter\",\n",
    "              'early_stopping_rounds': 150,\n",
    "             }\n",
    "\n",
    "n_folds = 10\n",
    "results = run_cv_model(train[train_cols].fillna(0), test[train_cols].fillna(0), train['redemption_status'], runCAT, cat_params, auc, 'cat', n_folds=n_folds)\n",
    "day = 4\n",
    "sub = 2\n",
    "name = f\"day_{day}_sub_{sub}\"\n",
    "tmp = dict(zip(test.id.values, results['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction_Outcome = pd.DataFrame()\n",
    "Prediction_Outcome['id'] = test.id.values\n",
    "Prediction_Outcome['redemption_status'] = Prediction_Outcome['id'].map(tmp)\n",
    "Prediction_Outcome.to_csv('Prediction.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
